{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192af4bd-f127-4257-b971-8f0c5f6317ca",
   "metadata": {},
   "source": [
    "## Katie Kimberling - Preprocessing of Liar Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126e524-8b2f-42e0-b505-0be7b1df9119",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac3364f9-c59e-4036-855b-2550b4ec9d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Downloaded Liar.csv to /home/ec2-user/SageMaker/data/Liar.csv\n",
      "✅ Downloaded Synthetic Financial Datasets.csv to /home/ec2-user/SageMaker/data/Synthetic Financial Datasets.csv\n",
      "✅ Downloaded WELFake_Dataset.csv to /home/ec2-user/SageMaker/data/WELFake_Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Define S3 bucket and file names\n",
    "s3_bucket = \"fake-news-raw-data\"\n",
    "s3_files = [\"Liar.csv\", \"Synthetic Financial Datasets.csv\", \"WELFake_Dataset.csv\"]\n",
    "local_folder = \"/home/ec2-user/SageMaker/data/\"\n",
    "\n",
    "# Ensure local directory exists\n",
    "os.makedirs(local_folder, exist_ok=True)\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# Download files from S3\n",
    "for file in s3_files:\n",
    "    local_path = os.path.join(local_folder, file)\n",
    "    s3_client.download_file(s3_bucket, file, local_path)\n",
    "    print(f\"✅ Downloaded {file} to {local_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88449319-68f1-4406-b075-e2ba10e9c945",
   "metadata": {},
   "source": [
    "## Import Python package \"stopwords\" to overlook commonly used words and articles (English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee5818f-9ebe-4c53-a279-1fc322eac88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e18ec09-accd-49bf-9fd6-d58270b01c07",
   "metadata": {},
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6026d4a-a63e-404c-ae35-f85af2c408aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acbbea4-b9e7-4731-91d1-40ba700c3e1f",
   "metadata": {},
   "source": [
    "## Ensure NLTK stopwords are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a6ba6c-f9de-4124-b7e2-7d9890cc7031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e5dbcb-e86f-44b4-a6d8-7b5bae37355e",
   "metadata": {},
   "source": [
    "## Load Liar.csv dataset and make pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270e03e4-3643-4374-a2d2-ff61cfc9d7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10240 entries, 0 to 10239\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Statement ID          10240 non-null  object \n",
      " 1   Lie_label             10240 non-null  object \n",
      " 2   Statement             10240 non-null  object \n",
      " 3   Topic                 10238 non-null  object \n",
      " 4   Speaker               10238 non-null  object \n",
      " 5   Speaker_Job_Title     7342 non-null   object \n",
      " 6   State                 8030 non-null   object \n",
      " 7   Speaker_party         10238 non-null  object \n",
      " 8   barely_true_counts    10238 non-null  float64\n",
      " 9   false_counts          10238 non-null  float64\n",
      " 10  half-true_counts      10238 non-null  float64\n",
      " 11  mostly_true_counts    10238 non-null  float64\n",
      " 12  pants_on_fire_counts  10238 non-null  float64\n",
      " 13  statement_mode        10138 non-null  object \n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "liar_clean = pd.read_csv(\"/home/ec2-user/SageMaker/data/Liar.csv\")\n",
    "\n",
    "# Display dataset info\n",
    "\n",
    "liar_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a062bd7a-8261-45a4-a21d-0e61a02d2d90",
   "metadata": {},
   "source": [
    "## Function to clean text using NLTK stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "762a82f1-f45f-4279-a0b9-fb72f0663648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_nltk(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "liar_clean[\"clean_statement\"] = liar_clean[\"Statement\"].apply(clean_text_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ec486-02bc-4d11-ade3-0ce948994fd2",
   "metadata": {},
   "source": [
    "## Convert numerical columns to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa46f8b-66f2-4b4a-853b-f0aa3a3b9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = [\"barely_true_counts\", \"false_counts\", \"half-true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\"]\n",
    "liar_clean[count_cols] = liar_clean[count_cols].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af357075-ef5c-418b-a583-51ac7b22c3e8",
   "metadata": {},
   "source": [
    "## Create a total misinformation score feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ec1bd6-763b-49a9-a386-2d9d4d4f601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_clean[\"total_misinfo_score\"] = liar_clean[count_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e17a4-e42b-4762-814e-1d13128cc782",
   "metadata": {},
   "source": [
    "## One-Hot Encoding for Speaker Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fdef977-36b6-49e1-bf6a-fd5246659a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False,drop=\"first\")\n",
    "encoded_party = encoder.fit_transform(liar_clean[[\"Speaker_party\"]])\n",
    "party_columns = encoder.get_feature_names_out([\"Speaker_party\"])\n",
    "liar_encoded_party = pd.DataFrame(encoded_party, columns=party_columns, index=liar_clean.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d04bbe-b158-487b-8a82-ce3d62bb09b5",
   "metadata": {},
   "source": [
    "## Merge and drop original categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45262a02-0605-4a7d-8317-90b789be35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_clean = pd.concat([liar_clean, liar_encoded_party], axis=1)\n",
    "liar_clean.drop([\"Speaker_party\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30b9e18-3d78-4f77-a07c-0e98c1898abc",
   "metadata": {},
   "source": [
    "## Balance dataset by oversampling minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c177407-11ec-4319-a8e4-9109d8596a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = liar_clean[liar_clean[\"Lie_label\"] == \"FALSE\"]\n",
    "minority_classes = liar_clean[liar_clean[\"Lie_label\"] != \"FALSE\"]\n",
    "minority_classes_upsampled = resample(minority_classes, replace=True, n_samples=len(majority_class), random_state=42)\n",
    "liar_balanced = pd.concat([majority_class, minority_classes_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a00a7b-3591-44ee-96ab-a9b4d72683c5",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dc8145b-51ba-4d08-bfc8-55215ae37243",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(liar_balanced, test_size=0.2, random_state=42, stratify=liar_balanced[\"Lie_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f000a-9843-413a-bf9a-f8fc087d21b0",
   "metadata": {},
   "source": [
    "## Save the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e98c9559-4997-4db7-bdbf-2d8d601296a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing on Liar dataset complete. Training and test datasets saved.\n"
     ]
    }
   ],
   "source": [
    "train_data.to_csv(\"/home/ec2-user/SageMaker/data/Liar_train.csv\", index=False)\n",
    "test_data.to_csv(\"/home/ec2-user/SageMaker/data/Liar_test.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessing on Liar dataset complete. Training and test datasets saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac07402-cf14-4f75-bae9-4450980b71b4",
   "metadata": {},
   "source": [
    "**References**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b6742-35af-442e-a054-d30f4fe26aa3",
   "metadata": {},
   "source": [
    "OpenAI. (2025). ChatGPT (March 20 version). [LLM]. https://chatgpt.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffc540-5cfd-4006-807c-dca72415b425",
   "metadata": {},
   "source": [
    "Python Tutorials. (2021, July 22). *NLTK stop words.* pythonspot. Accessed March 20, 2025 from https://pythonspot.com/nltk-stop-words/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2e606-fdc0-4265-b221-fa4b1a65821e",
   "metadata": {},
   "source": [
    "## Katie Kimberling's Data Training Liar Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe536d-3b50-41e0-b3e7-bb9d62a47cde",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06a5e79-90a5-4d56-a25d-03796f6c2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf14d5-2b32-4e9a-b421-e27574b21417",
   "metadata": {},
   "source": [
    "## Reload the train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64469691-2f30-435f-a083-7da64a47030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/home/ec2-user/SageMaker/data/Liar_train.csv\")\n",
    "test_data = pd.read_csv(\"/home/ec2-user/SageMaker/data/Liar_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c02c1cb-7ff8-4077-84d4-3d3ced7b3115",
   "metadata": {},
   "source": [
    "## Convert label and text into BlazingText format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "284fe87d-1b6c-412f-9852-0bc3ad91e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_blazingtext_format(df, text_col, label_col, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            label = f\"__label__{row[label_col]}\"\n",
    "            text = row[text_col]\n",
    "            f.write(f\"{label} {text}\\n\")\n",
    "\n",
    "# Paths to save formatted training and test data\n",
    "train_txt_path = \"/home/ec2-user/SageMaker/data/liar_train_blazing.txt\"\n",
    "test_txt_path = \"/home/ec2-user/SageMaker/data/liar_test_blazing.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa2704-bcd8-4560-b5f1-5d124e192815",
   "metadata": {},
   "source": [
    "## Apply formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52d33989-9b93-457c-b603-78d5d662f0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and test data formatted for BlazingText.\n"
     ]
    }
   ],
   "source": [
    "prepare_blazingtext_format(train_data, text_col=\"clean_statement\", label_col=\"Lie_label\", output_file=train_txt_path)\n",
    "prepare_blazingtext_format(test_data, text_col=\"clean_statement\", label_col=\"Lie_label\", output_file=test_txt_path)\n",
    "\n",
    "print(\"Training and test data formatted for BlazingText.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3542564-fd57-4ec6-bf44-e7b41ab19a01",
   "metadata": {},
   "source": [
    "## Define and upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "373cdd6c-ece9-474c-ad5d-a29dcf3b4e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded to S3.\n"
     ]
    }
   ],
   "source": [
    "# S3 upload paths\n",
    "s3_bucket = 'fake-news-raw-data'\n",
    "s3_prefix = 'blazingtext-data'\n",
    "train_s3_path = f'{s3_prefix}/liar_train_blazing.txt'\n",
    "test_s3_path = f'{s3_prefix}/liar_test_blazing.txt'\n",
    "\n",
    "# Upload to S3\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file(train_txt_path, s3_bucket, train_s3_path)\n",
    "s3.upload_file(test_txt_path, s3_bucket, test_s3_path)\n",
    "\n",
    "print(\"Files uploaded to S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b319ba-2f45-46ea-a45c-814a4cc1f7af",
   "metadata": {},
   "source": [
    "## Role, session, input paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3800ffff-380f-4ded-a4cd-d4c3dfffe9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Role and session\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# S3 input paths\n",
    "s3_train_input = f's3://{s3_bucket}/{train_s3_path}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8bdf2c-1ecf-403d-a6f0-5bdc2c1eba26",
   "metadata": {},
   "source": [
    "## BlazingText estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ca6e5b4-ac22-470d-b301-c6d9ead39416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m[03/31/25 18:09:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;94mINFO    \u001b[0m Same images used for training and \u001b]8;id=69498;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=184110;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         inference. Defaulting to image    \u001b[2m                 \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         scope: inference.                 \u001b[2m                 \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;94mINFO    \u001b[0m Ignoring unnecessary instance     \u001b]8;id=723862;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=388860;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#530\u001b\\\u001b[2m530\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         type: \u001b[3;35mNone\u001b[0m.                       \u001b[2m                 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "bt_image = sagemaker.image_uris.retrieve(\"blazingtext\", sess.boto_region_name)\n",
    "\n",
    "bt_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=bt_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    volume_size=5,\n",
    "    max_run=3600,\n",
    "    input_mode='File',\n",
    "    output_path=f's3://{s3_bucket}/blazingtext-output',\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d90ff5-c6f0-451a-87fe-792febed3030",
   "metadata": {},
   "source": [
    "# Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d18ca9c6-9505-4bcf-b9ed-3f796d6f51f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_estimator.set_hyperparameters(\n",
    "    mode='supervised',\n",
    "    epochs=10,\n",
    "    learning_rate=0.05,\n",
    "    vector_dim=100,\n",
    "    min_count=2,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e883e-d68e-4397-80f2-db4ef1d0f418",
   "metadata": {},
   "source": [
    "## Launch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94aa2182-e827-44d0-ae35-0667136b04f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;94mINFO    \u001b[0m SageMaker Python SDK will   \u001b]8;id=187072;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=682819;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         collect telemetry to help   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         us better understand our    \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         user's needs, diagnose      \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         issues, and deliver         \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         additional features.        \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         To opt out of telemetry,    \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         please disable via          \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         TelemetryOptOut parameter   \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         in SDK defaults config. For \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         more information, refer to  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://sagemaker.readthedo\u001b[0m \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mcs.io/en/stable/overview.ht\u001b[0m \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mml#configuring-and-using-de\u001b[0m \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mfaults-with-the-sagemaker-p\u001b[0m \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mython-sdk.\u001b[0m                  \u001b[2m                       \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;94mINFO    \u001b[0m Creating training-job with name:    \u001b]8;id=19790;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=195317;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         blazingtext-\u001b[1;36m2025\u001b[0m-03-31-18-09-17-700 \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m[03/31/25 18:09:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m Please check the troubleshooting    \u001b]8;id=573712;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=691111;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#1050\u001b\\\u001b[2m1050\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         guide for common errors:            \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://docs.aws.amazon.com/sagemak\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mer/latest/dg/sagemaker-python-sdk-t\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mroubleshooting.html#sagemaker-pytho\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mn-sdk-troubleshooting-create-traini\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mng-job\u001b[0m                              \u001b[2m               \u001b[0m\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateTrainingJob operation: No S3 objects found under S3 URL \"s3://fake-news-raw-data/blazingtext-data/liar_train_blazing.txt\" given in input data source. Please ensure that the bucket exists in the selected region (us-east-1), that objects exist under that S3 prefix, and that the role \"arn:aws:iam::372743750407:role/LabRole\" has \"s3:ListBucket\" permissions on bucket \"fake-news-raw-data\". Error message from S3: Access Denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingInput\n\u001b[1;32m      3\u001b[0m train_input \u001b[38;5;241m=\u001b[39m TrainingInput(s3_data\u001b[38;5;241m=\u001b[39ms3_train_input, content_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext/plain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mbt_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py:167\u001b[0m, in \u001b[0;36m_telemetry_emitter.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m caught_ex:\n\u001b[0;32m--> 167\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m caught_ex\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response  \u001b[38;5;66;03m# pylint: disable=W0150\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py:138\u001b[0m, in \u001b[0;36m_telemetry_emitter.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m start_timer \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Call the original function\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     stop_timer \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m    140\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m stop_timer \u001b[38;5;241m-\u001b[39m start_timer\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/estimator.py:1373\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_for_training(job_name\u001b[38;5;241m=\u001b[39mjob_name)\n\u001b[1;32m   1372\u001b[0m experiment_config \u001b[38;5;241m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[0;32m-> 1373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job \u001b[38;5;241m=\u001b[39m \u001b[43m_TrainingJob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_new\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1375\u001b[0m forward_to_mlflow_tracking_server \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/estimator.py:2514\u001b[0m, in \u001b[0;36m_TrainingJob.start_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   2511\u001b[0m train_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_train_args(estimator, inputs, experiment_config)\n\u001b[1;32m   2513\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain args after processing defaults: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, train_args)\n\u001b[0;32m-> 2514\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(estimator\u001b[38;5;241m.\u001b[39msagemaker_session, estimator\u001b[38;5;241m.\u001b[39m_current_job_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:1055\u001b[0m, in \u001b[0;36mSession.train\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, training_image_config, infra_check_config, container_entry_point, container_arguments, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy, remote_debug_config, session_chaining_config)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m   1051\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the troubleshooting guide for common errors: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, troubleshooting\n\u001b[1;32m   1052\u001b[0m         )\n\u001b[1;32m   1053\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m-> 1055\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_create_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:6678\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   6661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_intercept_create_request\u001b[39m(\n\u001b[1;32m   6662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   6663\u001b[0m     request: typing\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6666\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   6667\u001b[0m ):\n\u001b[1;32m   6668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   6669\u001b[0m \n\u001b[1;32m   6670\u001b[0m \u001b[38;5;124;03m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6676\u001b[0m \u001b[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   6677\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6678\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:1053\u001b[0m, in \u001b[0;36mSession.train.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   1046\u001b[0m troubleshooting \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#sagemaker-python-sdk-troubleshooting-create-training-job\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m )\n\u001b[1;32m   1050\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the troubleshooting guide for common errors: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, troubleshooting\n\u001b[1;32m   1052\u001b[0m )\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:1044\u001b[0m, in \u001b[0;36mSession.train.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating training-job with name: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, job_name)\n\u001b[1;32m   1043\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_training_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1046\u001b[0m     troubleshooting \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1047\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#sagemaker-python-sdk-troubleshooting-create-training-job\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateTrainingJob operation: No S3 objects found under S3 URL \"s3://fake-news-raw-data/blazingtext-data/liar_train_blazing.txt\" given in input data source. Please ensure that the bucket exists in the selected region (us-east-1), that objects exist under that S3 prefix, and that the role \"arn:aws:iam::372743750407:role/LabRole\" has \"s3:ListBucket\" permissions on bucket \"fake-news-raw-data\". Error message from S3: Access Denied"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_input = TrainingInput(s3_data=s3_train_input, content_type='text/plain')\n",
    "bt_estimator.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6457ddd4-ca16-44ae-96dc-2999a3239b85",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5073983-84b3-4f6c-8b8f-590825ce8b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = bt_estimator.deploy(initial_instance_count=1, instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df694a-2b91-4549-b06b-e78e6d216d09",
   "metadata": {},
   "source": [
    "## Prepare test data and extract predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce78ab-e53d-4ed9-9178-c6e1131a0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data for batch prediction (list of statements)\n",
    "test_statements = test_data['clean_statement'].tolist()\n",
    "\n",
    "# Predict labels\n",
    "predicted = predictor.predict(test_statements)\n",
    "\n",
    "# Extract predicted labels\n",
    "import json\n",
    "predicted_labels = [json.loads(x)['label'][0].replace(\"__label__\", \"\") for x in predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1188994-d0d5-4d72-8d25-42d680387eec",
   "metadata": {},
   "source": [
    "## Evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70f3f3-aabd-471c-b332-d08fdca1b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "true_labels = test_data['Lie_label'].tolist()\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45021d-9df9-4f48-a850-023fcb431364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
