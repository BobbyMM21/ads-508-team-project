{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192af4bd-f127-4257-b971-8f0c5f6317ca",
   "metadata": {},
   "source": [
    "## Katie Kimberling - Preprocessing of Liar Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126e524-8b2f-42e0-b505-0be7b1df9119",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac3364f9-c59e-4036-855b-2550b4ec9d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Downloaded Liar.csv to /home/ec2-user/SageMaker/data/Liar.csv\n",
      "✅ Downloaded Synthetic Financial Datasets.csv to /home/ec2-user/SageMaker/data/Synthetic Financial Datasets.csv\n",
      "✅ Downloaded WELFake_Dataset.csv to /home/ec2-user/SageMaker/data/WELFake_Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Define S3 bucket and file names\n",
    "s3_bucket = \"fake-news-raw-data\"\n",
    "s3_files = [\"Liar.csv\", \"Synthetic Financial Datasets.csv\", \"WELFake_Dataset.csv\"]\n",
    "local_folder = \"/home/ec2-user/SageMaker/data/\"\n",
    "\n",
    "# Ensure local directory exists\n",
    "os.makedirs(local_folder, exist_ok=True)\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# Download files from S3\n",
    "for file in s3_files:\n",
    "    local_path = os.path.join(local_folder, file)\n",
    "    s3_client.download_file(s3_bucket, file, local_path)\n",
    "    print(f\"✅ Downloaded {file} to {local_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88449319-68f1-4406-b075-e2ba10e9c945",
   "metadata": {},
   "source": [
    "## Import Python package \"stopwords\" to overlook commonly used words and articles (English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee5818f-9ebe-4c53-a279-1fc322eac88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e18ec09-accd-49bf-9fd6-d58270b01c07",
   "metadata": {},
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6026d4a-a63e-404c-ae35-f85af2c408aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acbbea4-b9e7-4731-91d1-40ba700c3e1f",
   "metadata": {},
   "source": [
    "## Ensure NLTK stopwords are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a6ba6c-f9de-4124-b7e2-7d9890cc7031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e5dbcb-e86f-44b4-a6d8-7b5bae37355e",
   "metadata": {},
   "source": [
    "## Load Liar.csv dataset and make pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270e03e4-3643-4374-a2d2-ff61cfc9d7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10240 entries, 0 to 10239\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Statement ID          10240 non-null  object \n",
      " 1   Lie_label             10240 non-null  object \n",
      " 2   Statement             10240 non-null  object \n",
      " 3   Topic                 10238 non-null  object \n",
      " 4   Speaker               10238 non-null  object \n",
      " 5   Speaker_Job_Title     7342 non-null   object \n",
      " 6   State                 8030 non-null   object \n",
      " 7   Speaker_party         10238 non-null  object \n",
      " 8   barely_true_counts    10238 non-null  float64\n",
      " 9   false_counts          10238 non-null  float64\n",
      " 10  half-true_counts      10238 non-null  float64\n",
      " 11  mostly_true_counts    10238 non-null  float64\n",
      " 12  pants_on_fire_counts  10238 non-null  float64\n",
      " 13  statement_mode        10138 non-null  object \n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "liar_clean = pd.read_csv(\"/home/ec2-user/SageMaker/data/Liar.csv\")\n",
    "\n",
    "# Display dataset info\n",
    "\n",
    "liar_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a062bd7a-8261-45a4-a21d-0e61a02d2d90",
   "metadata": {},
   "source": [
    "## Function to clean text using NLTK stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "762a82f1-f45f-4279-a0b9-fb72f0663648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_nltk(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "liar_clean[\"clean_statement\"] = liar_clean[\"Statement\"].apply(clean_text_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ec486-02bc-4d11-ade3-0ce948994fd2",
   "metadata": {},
   "source": [
    "## Convert numerical columns to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa46f8b-66f2-4b4a-853b-f0aa3a3b9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = [\"barely_true_counts\", \"false_counts\", \"half-true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\"]\n",
    "liar_clean[count_cols] = liar_clean[count_cols].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af357075-ef5c-418b-a583-51ac7b22c3e8",
   "metadata": {},
   "source": [
    "## Create a total misinformation score feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ec1bd6-763b-49a9-a386-2d9d4d4f601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_clean[\"total_misinfo_score\"] = liar_clean[count_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e17a4-e42b-4762-814e-1d13128cc782",
   "metadata": {},
   "source": [
    "## One-Hot Encoding for Speaker Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fdef977-36b6-49e1-bf6a-fd5246659a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False,drop=\"first\")\n",
    "encoded_party = encoder.fit_transform(liar_clean[[\"Speaker_party\"]])\n",
    "party_columns = encoder.get_feature_names_out([\"Speaker_party\"])\n",
    "liar_encoded_party = pd.DataFrame(encoded_party, columns=party_columns, index=liar_clean.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d04bbe-b158-487b-8a82-ce3d62bb09b5",
   "metadata": {},
   "source": [
    "## Merge and drop original categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45262a02-0605-4a7d-8317-90b789be35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_clean = pd.concat([liar_clean, liar_encoded_party], axis=1)\n",
    "liar_clean.drop([\"Speaker_party\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30b9e18-3d78-4f77-a07c-0e98c1898abc",
   "metadata": {},
   "source": [
    "## Balance dataset by oversampling minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c177407-11ec-4319-a8e4-9109d8596a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = liar_clean[liar_clean[\"Lie_label\"] == \"FALSE\"]\n",
    "minority_classes = liar_clean[liar_clean[\"Lie_label\"] != \"FALSE\"]\n",
    "minority_classes_upsampled = resample(minority_classes, replace=True, n_samples=len(majority_class), random_state=42)\n",
    "liar_balanced = pd.concat([majority_class, minority_classes_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a00a7b-3591-44ee-96ab-a9b4d72683c5",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dc8145b-51ba-4d08-bfc8-55215ae37243",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(liar_balanced, test_size=0.2, random_state=42, stratify=liar_balanced[\"Lie_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f000a-9843-413a-bf9a-f8fc087d21b0",
   "metadata": {},
   "source": [
    "## Save the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e98c9559-4997-4db7-bdbf-2d8d601296a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing on Liar dataset complete. Training and test datasets saved.\n"
     ]
    }
   ],
   "source": [
    "train_data.to_csv(\"/home/ec2-user/SageMaker/data/Liar_train.csv\", index=False)\n",
    "test_data.to_csv(\"/home/ec2-user/SageMaker/data/Liar_test.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessing on Liar dataset complete. Training and test datasets saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac07402-cf14-4f75-bae9-4450980b71b4",
   "metadata": {},
   "source": [
    "**References**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b6742-35af-442e-a054-d30f4fe26aa3",
   "metadata": {},
   "source": [
    "OpenAI. (2025). ChatGPT (March 20 version). [LLM]. https://chatgpt.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffc540-5cfd-4006-807c-dca72415b425",
   "metadata": {},
   "source": [
    "Python Tutorials. (2021, July 22). *NLTK stop words.* pythonspot. Accessed March 20, 2025 from https://pythonspot.com/nltk-stop-words/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2e606-fdc0-4265-b221-fa4b1a65821e",
   "metadata": {},
   "source": [
    "## Katie Kimberling's Data Training Liar Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe536d-3b50-41e0-b3e7-bb9d62a47cde",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06a5e79-90a5-4d56-a25d-03796f6c2640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf14d5-2b32-4e9a-b421-e27574b21417",
   "metadata": {},
   "source": [
    "## Reload the train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64469691-2f30-435f-a083-7da64a47030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/home/ec2-user/SageMaker/data/Liar_train.csv\")\n",
    "test_data = pd.read_csv(\"/home/ec2-user/SageMaker/data/Liar_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c02c1cb-7ff8-4077-84d4-3d3ced7b3115",
   "metadata": {},
   "source": [
    "## Convert label and text into BlazingText format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "284fe87d-1b6c-412f-9852-0bc3ad91e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_blazingtext_format(df, text_col, label_col, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            label = f\"__label__{row[label_col]}\"\n",
    "            text = row[text_col]\n",
    "            f.write(f\"{label} {text}\\n\")\n",
    "\n",
    "# Paths to save formatted training and test data\n",
    "train_txt_path = \"/home/ec2-user/SageMaker/data/liar_train_blazing.txt\"\n",
    "test_txt_path = \"/home/ec2-user/SageMaker/data/liar_test_blazing.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa2704-bcd8-4560-b5f1-5d124e192815",
   "metadata": {},
   "source": [
    "## Apply formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52d33989-9b93-457c-b603-78d5d662f0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and test data formatted for BlazingText.\n"
     ]
    }
   ],
   "source": [
    "prepare_blazingtext_format(train_data, text_col=\"clean_statement\", label_col=\"Lie_label\", output_file=train_txt_path)\n",
    "prepare_blazingtext_format(test_data, text_col=\"clean_statement\", label_col=\"Lie_label\", output_file=test_txt_path)\n",
    "\n",
    "print(\"Training and test data formatted for BlazingText.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3542564-fd57-4ec6-bf44-e7b41ab19a01",
   "metadata": {},
   "source": [
    "## Define and upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "373cdd6c-ece9-474c-ad5d-a29dcf3b4e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded to S3.\n"
     ]
    }
   ],
   "source": [
    "# S3 upload paths\n",
    "s3_bucket = 'fake-news-raw-data'\n",
    "s3_prefix = 'blazingtext-data'\n",
    "train_s3_path = f'{s3_prefix}/liar_train_blazing.txt'\n",
    "test_s3_path = f'{s3_prefix}/liar_test_blazing.txt'\n",
    "\n",
    "# Upload to S3\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file(train_txt_path, s3_bucket, train_s3_path)\n",
    "s3.upload_file(test_txt_path, s3_bucket, test_s3_path)\n",
    "\n",
    "print(\"Files uploaded to S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b319ba-2f45-46ea-a45c-814a4cc1f7af",
   "metadata": {},
   "source": [
    "## Role, session, input paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3800ffff-380f-4ded-a4cd-d4c3dfffe9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Role and session\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# S3 input paths\n",
    "s3_train_input = f's3://{s3_bucket}/{train_s3_path}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8bdf2c-1ecf-403d-a6f0-5bdc2c1eba26",
   "metadata": {},
   "source": [
    "## BlazingText estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ca6e5b4-ac22-470d-b301-c6d9ead39416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "bt_image = sagemaker.image_uris.retrieve(\"blazingtext\", sess.boto_region_name)\n",
    "\n",
    "bt_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=bt_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    volume_size=5,\n",
    "    max_run=3600,\n",
    "    input_mode='File',\n",
    "    output_path=f's3://{s3_bucket}/blazingtext-output',\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d90ff5-c6f0-451a-87fe-792febed3030",
   "metadata": {},
   "source": [
    "# Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d18ca9c6-9505-4bcf-b9ed-3f796d6f51f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_estimator.set_hyperparameters(\n",
    "    mode='supervised',\n",
    "    epochs=10,\n",
    "    learning_rate=0.05,\n",
    "    vector_dim=100,\n",
    "    min_count=2,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e883e-d68e-4397-80f2-db4ef1d0f418",
   "metadata": {},
   "source": [
    "## Launch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94aa2182-e827-44d0-ae35-0667136b04f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: blazingtext-2025-03-31-19-13-25-957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-31 19:13:29 Starting - Starting the training job...\n",
      "2025-03-31 19:13:43 Starting - Preparing the instances for training...\n",
      "2025-03-31 19:14:07 Downloading - Downloading input data...\n",
      "2025-03-31 19:14:47 Downloading - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[03/31/2025 19:15:05 WARNING 140022515312448] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[03/31/2025 19:15:05 WARNING 140022515312448] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[03/31/2025 19:15:05 INFO 140022515312448] nvidia-smi took: 0.025159597396850586 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[03/31/2025 19:15:05 INFO 140022515312448] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[03/31/2025 19:15:05 INFO 140022515312448] Processing /opt/ml/input/data/train/liar_train_blazing.txt . File size: 0.2905101776123047 MB\u001b[0m\n",
      "\u001b[34mRead 0M words\u001b[0m\n",
      "\u001b[34mNumber of words:  3536\u001b[0m\n",
      "\u001b[34mLoading validation data from \u001b[0m\n",
      "\u001b[34mValidation file cannot be opened!\u001b[0m\n",
      "\u001b[34m[03/31/2025 19:15:10 ERROR 140022515312448] Customer Error: Training did not complete successfully! Please check the logs for errors.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/amazon/lib/python3.8/site-packages/blazingtext/train.py\", line 75, in main\n",
      "    train_blazing_single(resource_config, train_config, data_config)\n",
      "  File \"/opt/amazon/lib/python3.8/site-packages/blazingtext/train_methods.py\", line 254, in train_blazing_single\n",
      "    raise exceptions.CustomerError(\"Training did not complete successfully! Please check the logs for errors.\")\u001b[0m\n",
      "\u001b[34mblazingtext.exceptions.CustomerError: Training did not complete successfully! Please check the logs for errors.\u001b[0m\n",
      "\n",
      "2025-03-31 19:15:26 Training - Training image download completed. Training in progress.\n",
      "2025-03-31 19:15:26 Uploading - Uploading generated training model\n",
      "2025-03-31 19:15:26 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job blazingtext-2025-03-31-19-13-25-957: Failed. Reason: ClientError: Training did not complete successfully! Please check the logs for errors., exit code: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingInput\n\u001b[1;32m      3\u001b[0m train_input \u001b[38;5;241m=\u001b[39m TrainingInput(s3_data\u001b[38;5;241m=\u001b[39ms3_train_input, content_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext/plain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mbt_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/estimator.py:1350\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1350\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/estimator.py:2720\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2718\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2720\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2721\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:5853\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   5832\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   5833\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   5834\u001b[0m \n\u001b[1;32m   5835\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5851\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   5852\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5853\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:8455\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(sagemaker_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   8452\u001b[0m             last_profiler_rule_statuses \u001b[38;5;241m=\u001b[39m profiler_rule_statuses\n\u001b[1;32m   8454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 8455\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrainingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   8457\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:8508\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   8502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   8503\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   8504\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8505\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8506\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8507\u001b[0m     )\n\u001b[0;32m-> 8508\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   8509\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8510\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8511\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8512\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job blazingtext-2025-03-31-19-13-25-957: Failed. Reason: ClientError: Training did not complete successfully! Please check the logs for errors., exit code: 0"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_input = TrainingInput(s3_data=s3_train_input, content_type='text/plain')\n",
    "bt_estimator.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6457ddd4-ca16-44ae-96dc-2999a3239b85",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5073983-84b3-4f6c-8b8f-590825ce8b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: blazingtext-2025-03-31-19-16-02-608\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AccessDeniedException) when calling the CreateModel operation: User: arn:aws:sts::908587188823:assumed-role/LabRole/SageMaker is not authorized to perform: sagemaker:CreateModel on resource: arn:aws:sagemaker:us-east-1:908587188823:model/blazingtext-2025-03-31-19-16-02-608 with an explicit deny in an identity-based policy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mbt_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mml.m5.large\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/estimator.py:1684\u001b[0m, in \u001b[0;36mEstimatorBase.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, use_compiled_model, wait, model_name, kms_key, data_capture_config, tags, serverless_inference_config, async_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m   1678\u001b[0m model\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m model_name\n\u001b[1;32m   1680\u001b[0m tags \u001b[38;5;241m=\u001b[39m update_inference_tags_with_jumpstart_training_tags(\n\u001b[1;32m   1681\u001b[0m     inference_tags\u001b[38;5;241m=\u001b[39mformat_tags(tags), training_tags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m   1682\u001b[0m )\n\u001b[0;32m-> 1684\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_instance_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeserializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserverless_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserverless_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvolume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvolume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_data_download_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_data_download_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontainer_startup_health_check_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontainer_startup_health_check_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_recommendation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_recommendation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/model.py:1695\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, accept_eula, endpoint_logging, resources, endpoint_type, managed_instance_scaling, inference_component_name, routing_config, **kwargs)\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# existing single model endpoint path\u001b[39;00m\n\u001b[0;32m-> 1695\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_sagemaker_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserverless_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserverless_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1702\u001b[0m     serverless_inference_config_dict \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1703\u001b[0m         serverless_inference_config\u001b[38;5;241m.\u001b[39m_to_request_dict() \u001b[38;5;28;01mif\u001b[39;00m is_serverless \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m     )\n\u001b[1;32m   1705\u001b[0m     production_variant \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mproduction_variant(\n\u001b[1;32m   1706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   1707\u001b[0m         instance_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1714\u001b[0m         routing_config\u001b[38;5;241m=\u001b[39mrouting_config,\n\u001b[1;32m   1715\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/model.py:980\u001b[0m, in \u001b[0;36mModel._create_sagemaker_model\u001b[0;34m(self, instance_type, accelerator_type, tags, serverless_inference_config, accept_eula, model_reference_arn)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;241m=\u001b[39m resolve_nested_dict_value_from_config(\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv,\n\u001b[1;32m    968\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnvironment\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    969\u001b[0m     MODEL_CONTAINERS_PATH,\n\u001b[1;32m    970\u001b[0m     sagemaker_session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session,\n\u001b[1;32m    971\u001b[0m )\n\u001b[1;32m    972\u001b[0m create_model_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    973\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    974\u001b[0m     role\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrole,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    978\u001b[0m     tags\u001b[38;5;241m=\u001b[39mformat_tags(tags),\n\u001b[1;32m    979\u001b[0m )\n\u001b[0;32m--> 980\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcreate_model_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:3976\u001b[0m, in \u001b[0;36mSession.create_model\u001b[0;34m(self, name, role, container_defs, vpc_config, enable_network_isolation, primary_container, tags)\u001b[0m\n\u001b[1;32m   3973\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3974\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 3976\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_create_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_model_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m name\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:6514\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   6497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_intercept_create_request\u001b[39m(\n\u001b[1;32m   6498\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   6499\u001b[0m     request: typing\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6502\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   6503\u001b[0m ):\n\u001b[1;32m   6504\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   6505\u001b[0m \n\u001b[1;32m   6506\u001b[0m \u001b[38;5;124;03m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6512\u001b[0m \u001b[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   6513\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/session.py:3964\u001b[0m, in \u001b[0;36mSession.create_model.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   3962\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreateModel request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m   3963\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3964\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3966\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDeniedException) when calling the CreateModel operation: User: arn:aws:sts::908587188823:assumed-role/LabRole/SageMaker is not authorized to perform: sagemaker:CreateModel on resource: arn:aws:sagemaker:us-east-1:908587188823:model/blazingtext-2025-03-31-19-16-02-608 with an explicit deny in an identity-based policy"
     ]
    }
   ],
   "source": [
    "predictor = bt_estimator.deploy(initial_instance_count=1, instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df694a-2b91-4549-b06b-e78e6d216d09",
   "metadata": {},
   "source": [
    "## Prepare test data and extract predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce78ab-e53d-4ed9-9178-c6e1131a0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data for batch prediction (list of statements)\n",
    "test_statements = test_data['clean_statement'].tolist()\n",
    "\n",
    "# Predict labels\n",
    "predicted = predictor.predict(test_statements)\n",
    "\n",
    "# Extract predicted labels\n",
    "import json\n",
    "predicted_labels = [json.loads(x)['label'][0].replace(\"__label__\", \"\") for x in predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1188994-d0d5-4d72-8d25-42d680387eec",
   "metadata": {},
   "source": [
    "## Evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70f3f3-aabd-471c-b332-d08fdca1b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "true_labels = test_data['Lie_label'].tolist()\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45021d-9df9-4f48-a850-023fcb431364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
